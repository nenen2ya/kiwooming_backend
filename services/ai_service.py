# services/ai_service.py
from pathlib import Path
import json
from openai import OpenAI
import requests

PROJECT_ROOT = Path(__file__).resolve().parents[2]
CONFIG_PATH = PROJECT_ROOT / "AI" / "project2" / "config.json"
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    config = json.load(f)

client = OpenAI(api_key=config["openai_api_key"])
model_id = config["kiwume_model_id"]

# ------------------------------------------
# ğŸ§  ìºì‹œ ì €ì¥ìš© ì „ì—­ ë©”ëª¨ë¦¬
# ------------------------------------------
ui_context_cache = {}
conversation_history = [{"role": "system", "content": config.get(
    "kiwooming_system_prompt",
    "ë‹¹ì‹ ì€ í‚¤ì›€ì¦ê¶Œ MTS ë‚´ AI ë°˜ë ¤ ì±—ë´‡ í‚¤ìš°ë°ì…ë‹ˆë‹¤. í™”ë©´ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¥ë½ì„ ì´í•´í•˜ê³  ë‹µí•˜ì„¸ìš”. í™”ë©´ êµ¬ì¡°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •í™•í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì „ë¶€ ì˜ ëª¨ë¥´ê² ë‹¤ê³  ëŒ€ë‹µí•©ë‹ˆë‹¤."
)}]


def get_ai_response(user_input: str, context: str | None = None) -> str:
    """
    - user_input: ì‚¬ìš©ìì˜ ì…ë ¥
    - context: í˜„ì¬ í™”ë©´ ì´ë¦„ (ì˜ˆ: 'Home', 'Quote')
    """

    try:
        # 1ï¸âƒ£ AST Parserì—ì„œ UI êµ¬ì¡° ë¶ˆëŸ¬ì˜¤ê¸° (ìºì‹œ ì¡´ì¬ ì‹œ ìŠ¤í‚µ)
        ui_json = ui_context_cache.get(context)
        if not ui_json and context:
            try:
                res = requests.get(f"http://127.0.0.1:4000/parse/{context}")
                if res.status_code == 200:
                    ui_json = res.json()
                    ui_context_cache[context] = ui_json
            except Exception as e:
                print("âš ï¸ UI íŒŒì„œ ì—°ê²° ì‹¤íŒ¨:", e)

        # 2ï¸âƒ£ RAG ê²€ìƒ‰ (optional)
        rag_context = ""
        try:
            rag_context = search_from_vectorDB(user_input)
        except:
            pass

        # 3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        [í˜„ì¬ í™”ë©´ ì´ë¦„]
        {context or 'ì •ë³´ ì—†ìŒ'}

        [í™”ë©´ êµ¬ì¡°(JSON ê¸°ë°˜ ì¸ì‹)]
        {json.dumps(ui_json, ensure_ascii=False, indent=2) if ui_json else 'UI ì •ë³´ ì—†ìŒ'}

        [ì°¸ê³  ì§€ì‹ (RAG ê²€ìƒ‰ ê²°ê³¼)]
        {rag_context or 'ì—†ìŒ'}

        [ì‚¬ìš©ì ë©”ì‹œì§€]
        {user_input}
        """

        conversation_history.append({"role": "user", "content": prompt})

        # 4ï¸âƒ£ OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model=model_id,
            messages=conversation_history,
            temperature=0.6,
            max_tokens=500,
        )

        reply = response.choices[0].message.content
        conversation_history.append({"role": "assistant", "content": reply})

        # 5ï¸âƒ£ ìºì‹œ ìœ ì§€
        if context and ui_json:
            ui_context_cache[context] = ui_json

        return reply

    except Exception as e:
        print("âŒ [get_ai_response ERROR]", e)
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}"


def search_from_vectorDB(query: str):
    """ (ì„ íƒ) RAG ê²€ìƒ‰ ë¡œì§ ìë¦¬ â€” ì¶”í›„ ì—°ê²° ê°€ëŠ¥ """
    return ""
